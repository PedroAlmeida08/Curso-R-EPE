---
title: "R para Análise de Dados"
author: "Bruno Crotman"
date: "17/08/2019"
output: 
    slidy_presentation:
        toc: true
        toc_depth: 3
        fig_caption: true

---

```{r setup, include=FALSE}

library(rlang)
library(bench)
library(ggbeeswarm)
library(scales)
library(Surrogate)
library(wbstats)
library(tidyverse)
library(magrittr)
library(knitr)
library(kableExtra)
library(DT)
library(lubridate)
library(cumstats)

library(electionsBR)
library(worldmet)
library(gapminder)
library(BETS)


knitr::opts_chunk$set(echo = TRUE)
```

# INTRODUÇÃO


## A máquina de escrever do meu avô

![](imagens/olivetti.jpg){width=50%} 


## Nem um Nobel escapa... 


...da maldição do erro operacional


![](imagens/erroexcel1.jpg)


## Homem foi a Lua há 50 anos

...e ainda...


![](imagens/erroexcel2.jpg)


## Objetivos do curso

Meta final: que vários dos processos de análise de dados da empresa passem a ser feitos dentro do fluxo de trabalho do R.

![](imagens/tidyverse.png)

Ao fim do curso o objetivo é que todos os fios da meada sejam puxados para que o aluno consiga continuar por si só usando a vasta documentação disponível.

## Por que programar?


Também amo o Excel, mas amo mais as seguintes vantagens:

* **Reprodutibilidade**. Muito mais fácil refazer uma análise com código do que point and click

* **Menor risco operacional**. A automatização é maior, a chance de erro na execução de um passo manual é nula

* **Menor risco de continuidade** caso haja imprevistos com a equipe. 

* **Maior flexibilidade**. Virtualmente tudo é possível

* **Manutenção** mais fácil

* **Controle de versão** de forma profissional

* **Mais fácil do que parece**


## Por que programar em R?

* Ela é feita para lidar com dados

* Comunidade de usuários gigante e cooperativa

* Ferramentas poderosas para comunicação dos resultados, em documentos ou aplicações

* Muitos pesquisadores em métodos quantitativos que estão no estado-da-arte publicam seus métodos em bibliotecas escritas em R

* Prazeroso programar


## Fluxo de trabalho

![](imagens/tidyverse_simplificado.png){width=50%} 


![](imagens/tidyverse.png){width=50%}


## Pequeno exemplo para motivação

É muito comum possuirmos dados gerados em planilhas ou em algum suporte de formarto estruturado. 

Neste exemplo, temos planilhas deste formato formato especificado

[Demo Planel](https://crotman.shinyapps.io/PNE-Planel)

## Ambiente R/RStudio

R é uma linguagem que é interpretada por um [engine](https://cran.r-project.org/) gratuito.

[RStudio](https://www.rstudio.com/) é o melhor ambiente de programação da linguagem R. A versão mais simples, que é totalmente funcional, é gratuita.

![](imagens/RStudio.png){width=50%}

Na visualização padrão, ele oferece um console para execução de comandos e uma janela com a visualização dos *environments*, ou seja, das variáveis que ele guarda na sessão atual.


## RStudio como console

No console é possível executar comandos, como o que atribui valor a uma variável

```{r atribuicao,  echo=TRUE}

x <- 1

```

Note que a atribuição é feita com `<-` e não com `=` como na maioria das linguagens.

>Dica: o atalho **alt** + **-** gera o sinal de atribuição

Os comandos que não atribuem valor a uma variável são ecoados na tela

```{r atribuicao2,  echo=TRUE}

x + 2

```

Veja o `[1]` no console. O R considera que tudo é um vetor. É uma linguagem muito baseada em operações vetoriais. Isso facilita muito as coisas quando se lida com dados.

## RStudio como IDE para um script

O console serve só para testes, aprendizado de novos comandos, debug, experiências etc.

Para as atividades mais comuns de análise de dados, e para que elas sejam reprodutíveis, é necessária a criação de scripts.

Eles são salvos em um arquivo de extensão ".r"



## Funcionalidades interessantes do RStudio

* Atalhos de teclado: **ctrl**+**enter** (rodar linhas selecionadas), **ctrl**+**shift**+**enter** (rodar script),  **ctrl**+**1** (foco no script), **ctrl**+**2** ** (foco no console), **ctrl**+**shift**+**F10** ** (reiniciar R), **ctrl**+**shift**+**C** (comentar/descomentar bloco)  ...

* Refactoring

* Document outline

* Pane: Files/Plots/Packages/Help/Viewer

* Pane: Environment/History/Connections/Git

* Jobs

* Controle de versão integrado com o Github

* Cheat sheets


## Baixando o material do github

Todo o material do curso está hospedado no Github, inclusive esta apresentação, escrita em RMarkdown.

Os exemplos de código, as imagens e os dados mostrados nesta apresentação estão inclusos no repositório do curso.

O repositório fica em [github/crotman/cursoR](https://github.com/crotman/CursoR).

Para baixar este repositório no RStudio, crie um projeto em File/New Project, do tipo Github e use o endereço do repositório: https://github.com/crotman/CursoR.git.

Todo material é disponibilizado sob a licença [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-nc-sa/4.0/)



# FUNDAMENTOS DA LINGUAGEM
    

## Tipos de valores "armazenados" por variáveis

Para o R, simplificando para o escopo deste curso, as variáveis "armazenam" os seguintes tipos:

* Vetores (vetores atômicos e listas)

```{r seq_int, echo=TRUE}
1L:10L
```

```{r list, echo=TRUE}

list("oi", 1L)

```

* Data Frames / Tibbles


```{r dataframe, echo=TRUE}
tibble(col1 = 1:10, col2 = 11:20 )
```

## Tipos de valores "armazenados" por variáveis (cont.)

* Funções (sim... uma variável pode "armazenar" uma função)

```{r funcoes, echo=TRUE}

f <- function(a, b){
    a + b
}

g <- f

g(1L, 2L)

```

* Environments 

```{r env, echo=TRUE}


e1 <- rlang::env(
    a = 1L,
    b = "sou o b",
    c = 1L:20L
)

get("b", e1)

```

## Tipos de valores "armazenados" por variáveis (cont.)


Existe orientação a objetos no R, mas não está no escopo deste curso

Note que não há variáveis que armazenam dado escalar, como já vimos.

Dentre os vetores há:


* vetores atômicos (seus elementos são do mesmo tipo primário)

* listas (seus elementos, que são vetores atômicos, são de tipos primários diferentes)

![Tipos de vetores](imagens/summary-tree.png){width=25%}

Fonte: [Advanced R](https://adv-r.hadley.nz/)


## Tipos de valores "armazenados" por variáveis (cont.)

Os vetores atômicos podem ser dos seguintes tipos:


![Tipos primários](imagens/summary-tree-atomic.png){width=25%}

Fonte: [Advanced R](https://adv-r.hadley.nz/)

## Tipos de vetores atômicos

* Logical é um tipo booleano, aceita TRUE ou FALSE

```{r bool, echo=TRUE}

booleano <- !TRUE 

booleano

```

* Integer é numérico e inteiro. Equivalente ao long do C++ (por isso o L na declaração)

```{r integer, echo=TRUE}

inteiro <- 8L 

typeof(inteiro + 1L)

typeof(inteiro + 1)


```

## Tipos de vetores atômicos (cont.)

* Double é numérico e aceita números decimais. Equivalente ao double do C++

```{r double, echo=TRUE}

double <- 0.1

double_cientifico <- 1.5e3

infinito <- Inf 
```


```{r, double_valor, echo=TRUE}

double

double_cientifico

infinito

```



## Cobinando vetores em vetores maiores usando c()

Uma das funções mais usadas do R é c(), que cria um vetor novo vetor combinando vetores.

```{r c, echo=TRUE}

c(1, 2, 3)

c(1, 2, 3, c(4, 5, 6))

1.4 : 9.4

```

## Outras formas de gerar um vetor

O operador `:` é usado para gerar um vetor com todos números que estão entre os operandos e são formados somando números inteiros ao primeiro operando.

```{r dois_pontos, echo=TRUE}

1L:10L

1.5:9.1



```

A função `seq()` é usada para criar um vetor de várias formas. 

Numa das formas especifica-se o valor inicial, o valor final e o incremento entre elementos do vetor. 


```{r seq, echo=TRUE}

seq(1, 9.99, 0.1)


```

## Parâmetros nomeados


Note que chamamos a função passando os parâmetros sem especificação de quais são eles. Eles são recebidos pela função dem específica. 

Mas no R também é possível passar parâmetros de forma nomeada. 

Clique em `F1` enquanto tem o cursor em cima da função e veja a ordem dos parâmetros. Veja que outros parâmetros que não utilizamos. Podemos usar `length.out` ao invés de `by`:

```{r seq_nome, echo=TRUE}


seq(1L, 10L, length.out = 10L)

seq(1L, 10L, length.out = 5L)

```

Outro parâmetro, `along.with`, deixa que criemos um vetor num intervalo determinado e o mesmo número de elementos do vetor passado por este parâmetro. 

```{r along, echo=TRUE}

seq(20, 100, along.with = 1:10)

```

## Valores faltantes NA

Valores faltantes ou desconecidos são representados por `NA`

```{r na, echo=TRUE}

a <- c(1L,NA)
a
```

O valor NA quase sempre contamina os cálculos

```{r na_contamina, echo=TRUE}
media <- mean(a)
media
```


mas...

```{r narm, echo=TRUE}
media <- mean(a, na.rm = TRUE)
media
```


A exceção são expressões que dão sempre o mesmo resultado independentemente do valor da variável

```{r na_exc, echo=TRUE}
NA ^ 0
NA | TRUE
NA & FALSE
```


A melhor forma de testar se existe um valor `NA` é `is.na`

```{r isna}

v <- c(1, NA, 2)

is.na(v)

```





## Programação com vetores

As operações do R são vetoriais. Numa operação entre um vetor e um escalar, a operação com o escalar é aplicada a cada elemento do vetor


```{r vetor, echo=TRUE}

1:5 * 2

```


```{r  vetor2, echo=TRUE}

1:10 / 10

```


Numa operação com vetores do mesmo tamanho, os elementos são pareados


```{r vetor_pareado, echo=TRUE}

1:10 * 1:10

```

## Programação com vetores - recycling

Outro conceito importante é o de *recycling*. 

Numa operação entre dois vetores de tamanhos diferentes, o vetor menor é repetido ciclicamente de forma a ficar com o mesmo tamanho do vetor maior. 

Lembra que toda variável no R é um vetor? 

Então... o escalar mostrado no primeiro código do slide anterior é um vetor de 1 elemento que sofre *recycling*


```{r recycling, echo=TRUE}

1:10 * 1:2

```

## Estruturas construídas a partir de vetores e listas

Existem estruturas mais complexas na linguagem construídas a partir de vetores e listas.

* Data Frame

* Matrix

* Array

* Factor

* Estruturas que representam datas

* Objetos (no paradigma de orientação a objetos)

Vamos passar pelo Data Frame agora. Depois por Factor e objetos que representam Datas


## Data Frames

Data Frames, e seu primo Tibble, são estruturas muito usadas em análises de dados feitas em R.

O dataframe consiste em um conjunto de vetores nomeados, com o mesmo número de elementos, que formam uma estrutura retangular, onde cada coluna é um vetor e cada linha n contém o n-ésimo elemento dos vetores.

É similar, em muitas características, a uma tabela de banco de dados.

Essa estrutura é chave no paradigma "Tidy" que usaremos com as bibliotecas **Tidy**verse

Tibble é uma adaptação do Data Frame para análise de dados. Discutir essas diferenças está fora do escopo do curso. Algumas diferenças serão citadas o longo do material e justificam o uso do Tibble.


```{r dataframetibble, echo=TRUE}

df <- 
    data.frame(
        nome = c("João", "Maria", "Zezinho", "Juquinha"), 
        idade = c(7, 8, 9, 10), 
        altura = c(10, 11)
    )
df


#tibble não aceita recycling em vetores de tamanho diferente de 1
tib <- 
    #try evita que o erro paralise toda a execução do script
    try(
        tibble(
            nome = c("João", "Maria", "Zezinho", "Juquinha"), 
            idade = c(7, 8, 9, 10), 
            altura = c(10, 11)
        )
    )
```



## Controle de fluxo

A linguagem oferece comandos de controle de fluxo similares aos de outras linguagens.

Podemos dividir os comandos de controle de fluxo em dois tipos:

* choices: execução alternativa de comandos

* loops: execução repetida de comandos


## Choices: `if`, `ifelse`

O comando `if` funciona para um valor lógico escalar


```{r if}
if (2 + 2 == 4) {
    "2 mais 2 são 4"
} else {
    "2 mais 2 não são 4"
}
```

Note o operador de comparação `==` e não `=`

A função `if_else` (da biblioteca dplyr) funciona de vetorial. `if_else` é mais rápida que a função `ifelse` da biblioteca `base`, mas só aceita argumentos de mesmo tipo no segundo e terceiro parâmetros

```{r jogo_pim}
jogo_do_pim_silvio_santos <- if_else(
    condition = 1:40 %% 4 == 0 ,
    true =  "PIM",
    false =  as.character(1:40)
)
jogo_do_pim_silvio_santos
```

Note o operador `%%` e a função de coerção de tipo `as.character` 


## Choices: `switch` e `case_when`

A cláusula `switch` e a função `dplyr::case_when` evitam que o programador tenha que criar muitos `if else` aninhados

```{r switch}
letra <- "b"

switch(
    letra,
    "a" = "começa com a",
    "b" = "começa com b",
    stop("deu ruim")
)

```

Note que a condição vai sendo testada na ordem e `stop` gera um erro

case_when serve ao caso vetorial

```{r case}
case_when(
    1:40 %% 10 == 0 ~ "dezena",
    1:40 %% 2 == 0 ~ "par",
    TRUE ~ as.character(1:40)
)
```


## Loops

A cláusula de loop mais usada e mais versátil é `for`

```{r for}
for(i in 1:5){ 
    print(i^2)
}
```

As cláusulas `next` e `break` modificam o comportamento, respectivamente caminhando direto para a próxima iteração e saindo do for

```{r next}
#next vai pra próxima iteração
for(i in 1:5){
    if (i %% 2 == 0){
        next
    }
    print(i)
}
```


```{r break}
#next sai do loop
for(i in 1:5){
    if (i %% 2 == 0){
        break
    }
    print(i)
}
```


## Loops: coisa do passado

Vamos ver que quase sempre é desnecessário usar loop para as tarefas que vamos executar.

O caráter vetorial da linguagem, aliado a funcionalidades das bibliotecas, faz com que a grande maioria dos loops sejam desnecessários.

O código fica mais limpo e expressivo e mais rápido. Às vezes MUITO mais rápido. Isso ocorre por motivos além do escopo do curso (alocação de memória, código interpretado x código compilado em C++ etc.)

O código abaixo usa loop e programação funcional, respectivamente. Programação funcional será abordada posteriormente no material. 


```{r com_loop, warning=FALSE}
com_loop <- function(n){
    x <- integer()
    for (i in 1:n){
        x <- c(x, i^2)
    }
    x
}

#programação funcional: aprenderemos posteriomente
sem_loop <- function(n){
    x <- 1:n %>% 
        map_dbl(function(x){x^2})
    x
}

```

Abaixo as três formas de fazer a mesma conta que terão a performance avaliada


```{r compara_loop}
com_loop(5)

sem_loop(5)

(1:5)^2

```

## Loops: coisa do passado (cont.)


A biblioteca `bench` oferece funções ótimas para avaliar a performance de pedaços pequenos de código.


```{r bench_loop, warning=FALSE, cache=TRUE}

resultados_perf <- mark(
    sem_loop(1e4),
    com_loop(1e4),
    (1:1e4)^2
)

#aprenderemos o que é %>% e select() posteriormente 
resultados_perf %>% 
    select(expression, min, median, `itr/sec` )

plot(resultados_perf)


```

## Exemplo de simulação: Monty Hall

Monty Hall era uma espécie de Sílvio Santos juvenil (sub 80) americano.

![](imagens/montyhall.png){width=20%}

Um dos seus jogos consistia em mostrar três portas ao otár... (ops) convidado. Em uma delas tem um carro.

Antes do resultado, o apresentador revela uma das portas e pergunta se o convidado que trocar a escolha.

![](imagens/montyhall2.jpg){width=20%}

O que vocês acham? Melhor trocar, manter a escolha original ou tanto faz?


## Simulando o Monty Hall

Note o que há de interessante no código (comentado)

```{r monty_hall}
set.seed(88)

joga_monty_hall <- function(troca){
    portas <- 1:3
    #sample() sorteia elementos com ou sem reposição
    porta_carro <- sample(portas, size = 1, replace = FALSE)
    primeira_escolha <- 1
    #Seleção negativa (retirando elementos)
    portas_pra_revelar <- portas[-c(porta_carro, primeira_escolha)]
    porta_revelada <- sample( c(portas_pra_revelar, portas_pra_revelar  ), 1)

    if(troca){
        escolha <- portas[-c(primeira_escolha, porta_revelada)]
    }
    else{
        escolha <- primeira_escolha
    }
    
    escolha == porta_carro
        
}

n <- 1000
#replicate executa múltiplas vezes um comando e armazena os resultados em uma estruturaúnica
troca <- replicate(n = n, joga_monty_hall(troca = TRUE))
fica  <- replicate(n = n, joga_monty_hall(troca = FALSE))
```

Resultados:

```{r result_monty_hall}
sum(troca)/n
sum(fica)/n
```

## Outra simulação: dá pra passar no CFA sem saber nada?


![](imagens/macacocomputador.jpg){width=20%}


Vamos ver... mas dá pra simular sem saber quase nada.

Vamos usar uma das funções da família `r<familia de distribuição de prob>()`. Neste caso, a `rbinom`, que simula a distribução binomial (aquela que equivale ao evento de jogar n moedas (ou alguma coisa com dois lados) para cima e ver quantas deram cara).


```{r cfa}

n_simul <- 10000
n_questoes <- 240
min_aprovacao <-  0.6
n_aprovado <- 240 * min_aprovacao
prob_questao <- 0.2

acertos <- rbinom(n = n_simul, size = n_questoes, prob = prob_questao   )

sum(acertos >= n_aprovado)/n_simul 

```

A chance é praticamente nula.

Na verdade, a grande massa da distribuição fica muito distante.


```{r mostra_cfa}

dado <- enframe(acertos/n_questoes)

mostra_chances <- function(acertos, n_questoes){
    ggplot(enframe(acertos/n_questoes)) +
        geom_density( aes(x = value)) +
        scale_x_continuous(
            labels = percent_format(accuracy = 1), 
            limits = c(0,1),
            breaks = seq(0, 1, 0.1) 
            ) +
        labs(x ="% Acertos") +
        geom_vline(xintercept = min_aprovacao, color = "red") +
        theme_light()
}

mostra_chances(acertos, n_questoes)

```



## Outra simulação: dá pra passar no CFA sabendo a um grau x ?

O exemplo anterior era muito simplista: ninguém chuta tudo.

Imagine que sabemos qual a chance de aparecer uma pergunta onde podemos descartar 0 alternativas, a chance de uma onde descartamos 1 e assim por diante.


```{r cfa_mais}
#definindo a chance podermos eliminar 0, 1, 2, ... 4 alternativas
fracao_eliminar_questoes <- c( 0.1, 0.1, 0.2, 0.25 , 0.35 ) 
#definindo o número de questões 
n_questoes_cada_elimina <- t(rmultinom(n_simul, size = n_questoes, fracao_eliminar_questoes))
probs_quando_elimina <- 1/(5:1)
acertos_concatenados <- 
    rbinom( 
        n =  n_simul * 5 , 
        size = as.vector(t(n_questoes_cada_elimina)), 
        prob = probs_quando_elimina  
    )
```


```{r cfa_1}
n_questoes_cada_elimina[1:4,]

```


```{r cfa_2}
acertos_concatenados[1:20]
```

```{r cfa_3}
matriz_acertos <- matrix(acertos_concatenados, byrow = TRUE, nrow = n_simul )

matriz_acertos[1:5,]
```


```{r cfa_4}
acertos <- rowSums(matriz_acertos)
sum(acertos > n_aprovado)/n_simul


```


```{r cfa_5}
mostra_chances(acertos, n_questoes)
```



## Exemplo inicial de visualização de dados


```{r ggplot, eval=TRUE, code = readLines("exemplos\\exemplo_inicial_ggplot.r")}



```


# TIDY DATA (obtenção e organização dos dados)

## Organizando os dados de forma tidy

Arrumar os dados de forma que as linhas sejam eventos e as colunas sejam atributos do evento ajuda muito a rodar modelos e construir visualizações eficientemente.

O que é o evento e o que é o atributo pode variar até para diferentes usos do mesmo dado. Mas a prática ajuda a determinar isso.

![](imagens/tidydata.png){width=70%}

## Tratamento de dados em passos: operador Pipe (`%>%`)

Normalmente os tratamentos de dados são feitos em múltiplos passos encadeados:


```{r gapminder}
#dados de exemplo
head(gapminder)

```

Vamos imaginar que queremos a média de PIB per capita por continente em 2007.

Note quanto código desnecessário há nestas linhas: variáveis que não precisavam ser nomeadas nem passadas explicitamente como parâmetro.

Este código desnecessário causa fadiga no programador e confunde o próprio programador e o leitor posterior do código.


```{r sem_pipe }
#vamos cobrir essas funções de tratamento posteriormente
gapminder_07 <- filter(gapminder, year == 2007)
gapminder_07_group_continente <- group_by(gapminder_07, continent)
gapminder_media_gdp_continente <- summarise(
    gapminder_07_group_continente, media_gdp = sum(gdpPercap * pop)/sum(pop)
)
resultado <- arrange(gapminder_media_gdp_continente, desc(media_gdp))

resultado

```

## Tratamento de dados em passos: operador Pipe (`%>%`) (cont.)

O operador pipe `%>%` faz o seguinte:

x %>% y(z) = y(x,z)

Ou seja, o primeiro operando é enfiado como primeiro parâmetro da função que está no segundo operando.

Isso faz com que possamos escrever o código anterior assim:

```{r pipe}

resultado <- gapminder %>% 
    filter(year == 2007) %>% 
    group_by(continent) %>% 
    summarise(
        media_gdp = sum(gdpPercap * pop) / sum(pop)
    ) %>% 
    arrange(desc(media_gdp))
    
resultado


```


Note que agora podemos interpretar o código facilmente como uma série de comandos de tratamento em cima dos dados. 

Não é por coincidência que as funções de tratamento das bibliotecas tidyverse que veremos adiante são verbos e recebem os dados como primeiro parâmetro.

**Agora o mais importante de tudo: O ATALHO PARA O ` %>% ` É CTRL + SHIFT + M**


## CRAN: uma Disneylândia dos dados?

CRAN é o repositório de bibliotecas mantido pelo R com contribuição de populares.

Além de funcionalidades estatísticas e funcionalidades para lidar com dados, há dados e funcionalidades para buscar dados online.

Usaremos várias das bases como exemplo.

A primeira é a do Banco Mundial, muito rica para quem gosta de dados socioeconômicos

Para acessar um indicador precisamos achá-lo na base de indicadores com a função `wbsearch()`

```{r banco_mundial}

#pattern é uma expressão regular. \\ serve para dizer que "(" é mesmo "(" 
#e não o ( usado nas operações de expressão regular (fora do escopo do curso)
indicadores <- wbsearch(pattern = "GINI index \\(World Bank estimate\\)")

indicadores


```

Sabendo o ID do indicador, podemos consultá-lo com a função `wb()`


```{r banco_mundial_2}

#mrv é most recent values. Pode ser usado para buscar os n valores mais recentes
gini = wb(indicator = "SI.POV.GINI", mrv= 10, POSIXct = TRUE)

head(gini)


```


## Funções básicas de tratamento (dplyr): select()

dplyr é uma das bibliotecas que fqzem parte do conjunto tidyverse

A função `select()` é usada para selecionar colunas do dataframe/tibble


```{r gini}

glimpse(gini)

```

```{r gini_select}

gini_select <- gini %>% 
    select(country, date, value, iso3c)

head(gini_select)

```

É possível usar a seleção negativa assim como fizemos com vetores

```{r gini_negativa}

gini_select2 <- gini_select %>% 
    select(-iso3c)

head(gini_select2)

```

## Funções básicas de tratamento (dplyr): select() (cont.)

Algumas funções *helpers* nos ajudam a usar a função `select` e são muito úteis para tratamentos mais elaborados.

Pra mostrar mais funcionalidades da função `select`, vamos usar uma base com dados eleitorais brasileiros, que retorna mais colunas


```{r  candidatos , cache=TRUE}

candidatos <- candidate_fed(2018)

glimpse(candidatos)

```

## Funções básicas de tratamento (dplyr): select() - helpers


```{r candidatos_select}

candidatos_select <- candidatos %>% 
    select(starts_with("NOME"))

datatable(head(candidatos_select))
    


```


```{r candidatos_select_ends }

candidatos_select <- candidatos %>% 
    select(ends_with("candidato"))

datatable(head(candidatos_select))
    


```

```{r contains }

candidatos_select <- candidatos %>% 
    select(contains("municipio"))

datatable(head(candidatos_select))


```

```{r ends_2}

candidatos_select <- candidatos %>% 
    select(ends_with("candidato"))

datatable(head(candidatos_select))


```


## Funções básicas de tratamento (dplyr): select() - helpers (cont.)


A função *helper* num_range ajuda a encontrar colunas do tipo `prefixo_n`. Isso é muito comum em bases de dados

A biblioteca `worldmet` retorna dados de estações meteorológicas espalhadas pelo planeta 

Primeiro é necessário encontrar o código da base desejada

```{r estacao, cache=TRUE}

estacao <- getMeta("heathrow", returnMap = TRUE)

estacao
    

```


## Funções básicas de tratamento (dplyr): select() - helpers (cont.)

A função abaixo retorna os dados de uma estação. Veja que alguns campos têm um sufixo _n 

```{r estacao_import, cache=TRUE }
dados_heathrow <- importNOAA(code = "037720-99999", year = 2019,
precip = TRUE, PWC = FALSE, parallel = TRUE)


glimpse(dados_heathrow)


```


A função *helper* `num_range` ajuda a selecionar essas colunas com prefixo comum e um sufixo numérico 



```{r num_range}

dados_heathrow_select <- dados_heathrow %>% 
    select( 
        date, 
        num_range("cl_", 1:3 ), 
        num_range("precip_", c(6, 12))  
    )


head(dados_heathrow_select)

```

Outra função útil é a `everything`, que ajuda, por exemplo, a passar algumas colunas para o início do *tibble*.


```{r everything}

dados_heathrow_select <- dados_heathrow %>% 
    select( 
        date, 
        air_temp,
        everything() 
    )


glimpse(dados_heathrow_select)




```
## Funções básicas de tratamento (dplyr): `mutate()`

A função mutate é usada para criar novas colunas no tibble

Notando que a coluna DATA_ELEICAO é um caracter, vamos criar uma coluna de tipo data.

```{r typeof}

typeof(candidatos$DATA_ELEICAO)


```


O jeito mais fácil de fazer isso é usando uma das funções da biblioteca `lubridate` que veremos em detalhes em seguida


```{r lubridate}

candidatos_com_data <- candidatos %>% 
    mutate(DATA_ELEICAO_TIPO_DATA = dmy(DATA_ELEICAO)) %>% 
    select(DATA_ELEICAO, DATA_ELEICAO_TIPO_DATA)

head(candidatos_com_data)

```


É possível substituir a um campo existente


```{r mutate_mesmo}

candidatos_com_data <- candidatos %>% 
    mutate(DATA_ELEICAO = dmy(DATA_ELEICAO)) %>% 
    select(DATA_ELEICAO)

head(candidatos_com_data)

```


## Funções básicas de tratamento (dplyr): `mutate()`


funções derivadas da `mutate` possibilitam a alteração de várias colunas ao mesmo tempo, usando os mesmos helpers que jã vimos para a `select` e uma função à escolha


```{r mutate_at}

candidatos_com_data <- candidatos %>% 
    mutate_at(vars(starts_with("DATA_")), dmy ) %>% 
    select(starts_with("DATA_"))


head(candidatos_com_data)


```

## Funções básicas de tratamento (dplyr) `mutate()` (cont.):

Outras funções úteis são as que fazem operações acumuladas e as operações de `lag()` e `lead()`

```{r bets, cache = TRUE}

series <- BETSsearch("exchange dollar")

series

```

No código abaixo, calculamos o retorno da série, a volatilidade histórica e a volatilidade EWMA

```{r bets_vol, cache = TRUE}

dolar <- BETSget(1) 

dolar_com_vol <- dolar %>% 
    filter(date > ymd("1994-07-01")) %>% 
    arrange(date) %>% 
    mutate(
        retorno = (value - lag(value))/value,
        retorno_quad = retorno^2,
        dia = row_number(),
        fator_ewma = (1/0.94)^dia*1e-20
    ) %>% 
    filter(!is.na(retorno)) %>% 
    mutate(vol = sqrt(cumvar(retorno)) * sqrt(252) ) %>% 
    mutate(vol_ewma = sqrt(cumsum(retorno_quad * fator_ewma)/cumsum(fator_ewma)) * sqrt(252) ) %>% 
    rename(dolar = value) %>% 
    select(
        date,
        dolar,
        retorno,
        vol,
        vol_ewma
    )

datatable(dolar_com_vol) %>% 
    formatPercentage(c("retorno", "vol", "vol_ewma"), 2)


```


```{r dolar_vol, cache=TRUE}

dolar_ajeitado <- dolar_com_vol %>% 
    gather(variavel, valor, - date)


dolar_ajeitado %>% 
    ggplot() +
    geom_line(aes(x = date, y = valor)) +
    facet_grid( variavel ~ . , scales = "free") +
    theme_light() 



```



## Funções básicas de tratamento (dplyr) `arrange()`:

A função `arrange` serve para ordenar o tibble.


```{r arrange}

dados_ordenados <- dados_heathrow %>% 
    arrange(date)

head(dados_ordenados)

```

A função `desc()` permite a ordenação decrescente


```{r desc}

dados_ordenados <- dados_heathrow %>% 
    arrange(desc(date))

head(dados_ordenados)



```




## Funções básicas de tratamento (dplyr) `group_by()`:


A função `group_by` será bastante usada..

Quem conhece SQL pode estranhar um pouco o comportamento desta função, pois ela não agrupa os dados diminuindo o número de linhas imediatamente.

Mas veja que ela indica que há agrupamento


```{r group_by}

gini_agrupado <- gini %>% 
    select(country, date, value) %>% 
    group_by(country) 
    
gini_agrupado


```


## Funções básicas de tratamento (dplyr) `group_by()` (cont.):

Para várias operações, entretanto, o agrupamento faz com que o comportamento seja diferente

Uma operação bastante usada é numerar as linhas de um tibble.

No tibble agrupado, essa operação acontece em cada grupo.

```{r row_number}

gini_agrupado %<>% arrange(country, date) %>% 
    mutate(linha = row_number())


datatable(gini_agrupado)


```



## Funções básicas de tratamento (dplyr) `group_by()` (cont.):


As funções `lag()` e `lead()` funcionam dentro de cada grupo (o primeiro value de um grupo não acessa o valor do outro grupo com `lag()` .

```{r lag}

gini_agrupado %<>% mutate(
    value_ant = lag(value),
    delta_value = value - value_ant
    )

datatable(gini_agrupado)

```



## Funções básicas de tratamento (dplyr) `group_by()` (cont.):


A função `group_by` só leva a uma sumarização, ou seja, só transforma o tibble em um tibble com o número de linhas igual ao número de grupos, quando executamos a função `summarise()`


```{r summarise}

maiores_temp_dia <- dados_heathrow %>% 
    group_by(date(date)) %>% 
    summarise(
        maxima = max(air_temp),
        minima = min(air_temp),
        media = mean(air_temp)
    )


datatable(maiores_temp_dia) %>% 
    formatRound(c("maxima", "minima", "media"), 1)


```



A função `top_n` retorna os n maiores valores. Se o tibble estiver agrupado, pra cada grupo.



```{r top_n}


maiores_temp_dia <- dados_heathrow %>% 
    group_by(date(date)) %>% 
    top_n(1, air_temp) %>% 
    ungroup() %>% 
    mutate(
        hora = hour(date),
        estacao = 
            case_when(
                month(date) %in% 1:3 ~ "Inverno",
                month(date) %in% 7:9 ~ "Verão",
                TRUE ~ "Outono/Primavera"
                
            )
    ) %>% 
    select(hora, estacao, air_temp)

ggplot(maiores_temp_dia) +
    geom_density( aes(x = hora, color = estacao )) +
    theme_light()




```


## Leitura de dados de arquivos

Até agora acessamos dados que estavam disponíveis em bibliotecas, mas muitas vezes encontramos dados em arquivos.

De modo geral, as funções da biblioteca `readr` são mas rápidas do que as da biblioteca base, e também mostram barra de progresso no console. É possível reconhecê-las pelo `_` ao invés de `.` 

O portal da CVM é uma das minas de ouro de dados


O código abaixo baixa os dados que ainda não estão na nossa base

```{r fundos, warning=FALSE}

existem <- tibble(arquivo = list.files("dados/fundos"))


salva <- function(dado){
    
    endereco <- pull(dado, endereco)
    arquivo <- pull(dado, arquivo)
    
    print(endereco)
    conteudo <- read_csv2(endereco)
    
    write_csv(conteudo, paste0("dados/fundos/",arquivo))
    
}



baixa_faltantes <- tibble(data_dado = seq(ymd("2017-01-01"), by = "month", ymd(today()) )) %>% 
    mutate(data_formato = stamp_date("999912")(data_dado)) %>% 
    mutate(
        endereco = paste0(
            "http://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/",
            "inf_diario_fi_",
            data_formato,
            ".csv")) %>% 
    mutate(arquivo = paste("inf_diario_fi_",data_formato,".csv")) %>% 
    anti_join(existem, by = c("arquivo" = "arquivo")) %>% 
    select(-data_formato) %>% 
    group_by(data_dado) %>% 
    nest() %>% 
    mutate(data = map(data, salva ))


le_arquivo <- function(lista_arquivo){
    
    arquivo <- pull(lista_arquivo, arquivo)
    
    conteudo <- read_csv(arquivo)
    
    print(arquivo)
    
    conteudo
    
}


todos_os_fundos <- tibble(arquivo = list.files("dados/fundos")) %>%
    mutate(arquivo = paste0("dados/fundos/",arquivo )) %>% 
    group_by(row_number()) %>% 
    nest() %>% 
    mutate(data = map(data, le_arquivo)) %>% 
    unnest()


head(todos_os_fundos)

```





```{r cadastro_fundos, cache=TRUE, warning=FALSE}

cadastro_fundos <- read_csv2("http://dados.cvm.gov.br/dados/FIE/CAD/DADOS/inf_cadastral_fie.csv", locale =  locale(encoding = "latin1") )


```


```{r cotas_verde, cache=TRUE }

cotas_verde <- todos_os_fundos %>% 
    filter(CNPJ_FUNDO == "07.455.507/0001-89" )


cotas_verde

```



## Funções de junção (dplyr)

## Funções de pivot (tidyr)

## Funções de pivot (tidyselect)

manobras com vars, starts_with, num_range etc

## Tratamento de strings (caracteres) com stringr

## Tratamento de datas (lubridate)

## Tratamento de dados categóricos (forcats) 

# VISUALIZAÇÃO DE DADOS 

# PROGRAMAÇÃO FUNCIONAL 

## Simulação CFA com vários parâmetros


```{r}

n_simul <- 10000
n_questoes <- 240
min_aprovacao <-  0.6
n_aprovado <- 240 * min_aprovacao
prob_questao <- 0.2


estimar_chance <-  function(...){
    
    print("aqui")
    fracao_eliminar_questoes <- as.vector(...)
    
    #definindo o número de questões 
    n_questoes_cada_elimina <- t(rmultinom(n_simul, size = n_questoes, fracao_eliminar_questoes))
    probs_quando_elimina <- 1/(5:1)
    acertos_concatenados <- 
        rbinom( 
            n =  n_simul * 5 , 
            size = as.vector(t(n_questoes_cada_elimina)), 
            prob = probs_quando_elimina  
        )
    
    matriz_acertos <- matrix(acertos_concatenados, byrow = TRUE, nrow = n_simul )
    
    acertos <- rowSums(matriz_acertos)
    sum(acertos > n_aprovado)/n_simul
}


#definindo a chance podermos eliminar 0, 1, 2, ... 4 alternativas
resultados <- RandVec(n = 5, m = 100) %>% 
    .$RandVecOutput %>% 
    t() %>% 
    as_tibble() %>% 
    mutate(id = row_number()) %>% 
    group_by(id) %>% 
    nest() %>% 
    mutate(data_fica = data) %>%     
    mutate(data = map(data, estimar_chance) ) %>% 
    unnest()







```


## Aplicação de funções a dataframes (purrr)

## map-reduce

# EXECUTANDO MODELOS

## Execução de modelos com broom

## Execução de modelos com caret

# SÉRIES TEMPORAIS

## Repositórios de séries temporais

## Manipulação de séries temporais

## Biblioteca Forecast

# COMUNICANDO OS RESULTADOS

## Criando relatórios com R Markdown

## Livros

[Referência Bookdown](https://bookdown.org/yihui/bookdown/html.html)

## Criando visualizações interativas com Shiny









